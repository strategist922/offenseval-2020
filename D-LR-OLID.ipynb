{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misspellings of curse words?  \n",
    "\n",
    "When building vocab, consider punctuation. Tokenize it first? Right now it just splits on whitespace. Moses probably has something for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(1234) # help reproducibility\n",
    "olidData = 'data/OLIDv1.0/olid-training-v1.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "olid = open(olidData)\n",
    "df = pd.read_csv(olid, sep='\\t')\n",
    "olid.close()\n",
    "df = df.drop(df.columns[[0,3,4]], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet subtask_a\n",
      "0  @USER She should ask a few native Americans wh...       OFF\n",
      "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF\n",
      "2  Amazon is investigating Chinese employees who ...       NOT\n",
      "3  @USER Someone should'veTaken\" this piece of sh...       OFF\n",
      "4  @USER @USER Obama wanted liberals &amp; illega...       NOT\n"
     ]
    }
   ],
   "source": [
    "data_top = df.head()\n",
    "print(data_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.array(df['tweet'])\n",
    "offen = np.array(df['subtask_a'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "text_train, text_test, offen_train, offen_test = train_test_split(text, offen, test_size=0.2, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "pipe = Pipeline([\n",
    "    ('feats', FeatureUnion([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ])),\n",
    "    \n",
    "    ('lr' ,LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_parms = [{\n",
    "    'feats__tfidf__max_features' : [100,500],\n",
    "    'feats__tfidf__ngram_range' : [(1,1),(1,2)],\n",
    "    'feats__cvec__max_features' : [100,500],\n",
    "    'feats__cvec__ngram_range' : [(1,1),(1,2)],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pipe.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7553\n",
      "Precision: 0.7468\n",
      "Recall: 0.7553\n",
      "F1 Score: 0.746\n"
     ]
    }
   ],
   "source": [
    "get_metrics(offen_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(pipe, param_grid= pipe_parms, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7553\n",
      "Precision: 0.7468\n",
      "Recall: 0.7553\n",
      "F1 Score: 0.746\n"
     ]
    }
   ],
   "source": [
    "train_predict_display_model(classifier=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Evaluation metrics\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    print('Accuracy:', np.round(\n",
    "                        metrics.accuracy_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        4))\n",
    "    print('Precision:', np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('Recall:', np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('F1 Score:', np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "                        \n",
    "def train_predict_display_model(classifier, \n",
    "                        train_features=text_train, \n",
    "                        test_features=text_test, \n",
    "                        train_labels=offen_train, \n",
    "                        test_labels=offen_test):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    get_metrics(test_labels,predictions)   \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
