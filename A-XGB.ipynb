{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 0.04s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "import csv\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "olid_data = 'data/OLIDv1.0/olid-training-v1.0.tsv'\n",
    "\n",
    "np.random.seed(1234) # help reproducibility\n",
    "\n",
    "# y == 0 if not offensive\n",
    "# y == 1 if offensive\n",
    "start = time()\n",
    "with open(olid_data, encoding='utf-8') as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    x_raw = []\n",
    "    y = []\n",
    "    for r in raw:\n",
    "        x_raw.append(r[1])\n",
    "        y.append(0 if r[2] == 'NOT' else 1)\n",
    "    x_raw = x_raw[1:]\n",
    "    y = np.array(y[1:])\n",
    "    bad_words = [row[:-1] for row in f.readlines()[1:]]\n",
    "print('Loaded data in %.2fs' % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(x, y):\n",
    "    # Shuffle x and y together\n",
    "    state = np.random.get_state()\n",
    "    i = np.arange(x.shape[0])\n",
    "    np.random.shuffle(i)\n",
    "    np.random.set_state(state)\n",
    "    k = np.arange(y.shape[0])\n",
    "    np.random.shuffle(k)\n",
    "    return x[i, :], y[k] # shuffling a sparse matrix is weird\n",
    "\n",
    "def report(y, y_hat, metrics=['accuracy', 'precision', 'recall', 'f1-weighted', 'f1-macro']):\n",
    "    results = []\n",
    "    if 'accuracy' in metrics or 'acc' in metrics:\n",
    "        results.append(skmetrics.accuracy_score(y, y_hat))\n",
    "    if 'precision' in metrics:\n",
    "        results.append(skmetrics.precision_score(y, y_hat))\n",
    "    if 'recall' in metrics:\n",
    "        results.append(skmetrics.recall_score(y, y_hat))\n",
    "    if 'f1-weighted' in metrics:\n",
    "        results.append(skmetrics.f1_score(y, y_hat, average='weighted'))\n",
    "    if 'f1-macro' in metrics:\n",
    "        results.append(skmetrics.f1_score(y, y_hat, average='macro'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer = TweetTokenizer()  \n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                             strip_accents='unicode', \n",
    "                             lowercase=True,\n",
    "                             sublinear_tf=True,\n",
    "                             min_df=9,\n",
    "                             stop_words='english'\n",
    "                            )\n",
    "x = vectorizer.fit_transform(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md=1, lr=0.310000, n=2000\n",
      "acc     p       r       f1-w    f1-m    time    \n",
      "0.7591  0.7292  0.4529  0.7415  0.6965  10.27s\n",
      "0.7659  0.7491  0.4515  0.7475  0.7017  10.13s\n",
      "0.7779  0.8169  0.4895  0.7613  0.7283  10.26s\n",
      "0.7810  0.7148  0.4575  0.7648  0.7062  10.20s\n",
      "0.7711  0.7519  0.4624  0.7538  0.7082  10.14s\n",
      "0.7613  0.7323  0.4467  0.7430  0.6959  10.17s\n",
      "0.7727  0.7378  0.4603  0.7557  0.7064  10.17s\n",
      "0.7576  0.7435  0.4425  0.7383  0.6941  10.21s\n",
      "0.7666  0.7222  0.4760  0.7517  0.7066  10.17s\n",
      "0.7606  0.7085  0.4750  0.7460  0.7015  10.17s\n",
      "average:\n",
      "0.7674  0.7406  0.4614  0.7504  0.7045  10.19s\n",
      "\n",
      "md=1, lr=0.320000, n=2000\n",
      "acc     p       r       f1-w    f1-m    time    \n",
      "0.7606  0.7312  0.4574  0.7434  0.6990  10.19s\n",
      "0.7659  0.7454  0.4560  0.7481  0.7028  10.21s\n",
      "0.7779  0.8125  0.4937  0.7618  0.7291  10.18s\n",
      "0.7787  0.7034  0.4625  0.7635  0.7052  10.15s\n",
      "0.7696  0.7428  0.4670  0.7531  0.7078  10.24s\n",
      "0.7636  0.7370  0.4512  0.7456  0.6991  10.16s\n",
      "0.7779  0.7481  0.4720  0.7618  0.7140  10.25s\n",
      "0.7613  0.7519  0.4491  0.7425  0.6991  10.30s\n",
      "0.7659  0.7197  0.4760  0.7510  0.7059  10.20s\n",
      "0.7576  0.7003  0.4727  0.7431  0.6982  10.21s\n",
      "average:\n",
      "0.7679  0.7392  0.4658  0.7514  0.7060  10.21s\n",
      "\n",
      "md=1, lr=0.330000, n=2000\n",
      "acc     p       r       f1-w    f1-m    time    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def test(model):\n",
    "    k = 10\n",
    "    kf = KFold(n_splits=k)\n",
    "    average_acc = 0\n",
    "    print(6 * '%-8s' % ('acc', 'p', 'r', 'f1-w', 'f1-m', 'time'))\n",
    "    averages = np.array([0] * 6, dtype='float')\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        start = time()\n",
    "        # Split based on k-fold\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_train, y_train = shuffle_together(x_train, y_train)\n",
    "        clf = model.fit(x_train, y_train)\n",
    "        y_hat = clf.predict(x_test)\n",
    "        vals = report(y_test, y_hat) + [time() - start]\n",
    "        averages += vals\n",
    "        print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs' % tuple(vals))\n",
    "    print('average:')\n",
    "    averages /= k\n",
    "    print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs' % tuple(averages))\n",
    "\n",
    "    '''\n",
    "MD  LR    N     F1-w    F1-m\n",
    "3   0.90  100   0.7452\n",
    "2   0.53  500   0.7510         # explored\n",
    "2   0.40  1000  0.7513  0.7075 # explored\n",
    "1   0.63  500   0.7514  0.7047 # explored\n",
    "1   0.63  1000  0.7547  0.7095 # explored\n",
    "1   0.4   2000          0.7062\n",
    "'''\n",
    "\n",
    "for md in [1]:\n",
    "    for lr in [i / 100 for i in range(31, 61)]:\n",
    "        for n in [2000]:\n",
    "            print('md=%d, lr=%f, n=%d' % (md, lr,n))\n",
    "            model = XGBClassifier(max_depth=md, learning_rate=lr, n_estimators=n)\n",
    "            test(model)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
