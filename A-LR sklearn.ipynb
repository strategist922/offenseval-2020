{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "olid_data = 'data/OLIDv1.0/olid-training-v1.0.tsv'\n",
    "kaggle_data_folder = 'data/jigsaw/'\n",
    "bad_words_data = 'data/trimmed-bad-words.txt'\n",
    "glove_data = 'data/glove.twitter.27B/glove.twitter.27B.25d.txt' # 25, 50, 100, or 200 D\n",
    "\n",
    "np.random.seed(1234) # help reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 1.88s\n"
     ]
    }
   ],
   "source": [
    "# y == 0 if not offensive\n",
    "# y == 1 if offensive\n",
    "start = time()\n",
    "with open(olid_data) as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    x_raw = []\n",
    "    y = []\n",
    "    for r in raw:\n",
    "        x_raw.append(r[1])\n",
    "        y.append(0 if r[2] == 'NOT' else 1)\n",
    "    x_raw = x_raw[1:]\n",
    "    y = np.array(y[1:])\n",
    "\n",
    "with open(kaggle_data_folder + 'train.csv') as f:  \n",
    "    raw = csv.reader(f, delimiter=',')\n",
    "    kaggle_x_raw = []\n",
    "    kaggle_y = []\n",
    "    for r in raw:\n",
    "        kaggle_x_raw.append(r[1])\n",
    "        kaggle_y.append(0 if all(x == '0' for x in r[2:]) else 1)\n",
    "    kaggle_x_raw = kaggle_x_raw[1:]\n",
    "    kaggle_y = np.array(kaggle_y[1:])\n",
    "     \n",
    "with open(bad_words_data) as f:\n",
    "    bad_words = [row[:-1] for row in f.readlines()[1:]]\n",
    "\n",
    "print('Loaded data in %.2fs' % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe in 25.22s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "glove = {}\n",
    "with open(glove_data) as f:\n",
    "    raw = [row.split() for row in f.readlines()]\n",
    "    for r in raw:\n",
    "        glove[r[0]] = np.array([float(v) for v in r[1:]])\n",
    "print('Loaded GloVe in %.2fs' % (time() - start))\n",
    "# On my mac, loads 25D in 30s, 50D in 100s, 100D in 630s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "    \n",
    "def bow():\n",
    "    # Build vocabulary from OLID data only\n",
    "    start = time()\n",
    "    vocab = {}\n",
    "    i = 0 # index of unique word\n",
    "    for tweet in x_raw: \n",
    "        for word in tokenizer.tokenize(tweet):\n",
    "            if word not in vocab:\n",
    "                vocab[word] = i\n",
    "                i += 1\n",
    "    print('Vocabulary built in %.2fs' % (time() - start))\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize, vocabulary=vocab, lowercase=True)\n",
    "    return vectorizer.fit_transform(x_raw) # + kaggle_x_raw)\n",
    "\n",
    "def sum_glove():\n",
    "    x = []\n",
    "    embedding = np.zeros(glove['.'].shape)\n",
    "    for tweet in x_raw:\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        for word in tokens:\n",
    "            if word in glove:\n",
    "                embedding += glove[word]\n",
    "        x.append(embedding)#/ len(tokens))\n",
    "    x = np.array(x)\n",
    "    x = x - np.min(x, axis=1).reshape(x.shape[0], 1)\n",
    "    x = x / np.max(x, axis=1).reshape(x.shape[0], 1)\n",
    "    return np.array(x)\n",
    "\n",
    "x = sum_glove()\n",
    "#kaggle_x = x[len(x_raw):]\n",
    "#x = x[:len(x_raw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(x, y):\n",
    "    # Shuffle x and y together\n",
    "    state = np.random.get_state()\n",
    "    i = np.arange(x.shape[0])\n",
    "    np.random.shuffle(i)\n",
    "    np.random.set_state(state)\n",
    "    k = np.arange(y.shape[0])\n",
    "    np.random.shuffle(k)\n",
    "    return x[i, :], y[k] # shuffling a sparse matrix is weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.6631\n",
      "acc: 0.6654\n",
      "acc: 0.6420\n",
      "acc: 0.6979\n",
      "acc: 0.6684\n",
      "acc: 0.6669\n",
      "acc: 0.6767\n",
      "acc: 0.6586\n",
      "acc: 0.6699\n",
      "acc: 0.6677\n",
      "average acc: 0.6677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "average_acc = 0\n",
    "for train_index, test_index in kf.split(x):\n",
    "    # Split based on k-fold\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # Append kaggle data to training data\n",
    "    # x_train = vstack((x_train, kaggle_x))\n",
    "    # y_train = np.concatenate((y_train, kaggle_y))\n",
    "    x_train, y_train = shuffle_together(x_train, y_train)\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=300).fit(x_train, y_train)\n",
    "    y_hat = clf.predict(x_test)\n",
    "    acc = y_hat[np.where(y_hat == y_test)].size / y_test.size\n",
    "    average_acc += acc\n",
    "    print('acc: %.4f' % acc)\n",
    "print('average acc: %.4f' % (average_acc / k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\n",
    "    [\n",
    "        [1, 2],\n",
    "        [3, 4]\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(m[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.min(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
