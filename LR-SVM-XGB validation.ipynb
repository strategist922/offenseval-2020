{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "training_data = 'data/OLIDv1.0/olid-training-v1.0.tsv'\n",
    "test_data = 'data/OLIDv1.0/testset-levela.tsv'\n",
    "test_labels = 'data/OLIDv1.0/labels-levela.csv'\n",
    "hashtags = 'data/olid_segmentations.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(x, y):\n",
    "    # Shuffle x and y together\n",
    "    i = np.arange(x.shape[0])\n",
    "    np.random.shuffle(i)\n",
    "    return x[i, :], y[i] # shuffling a sparse matrix is weird\n",
    "\n",
    "def report(y, y_hat, M=['accuracy', 'precision', 'recall', 'f1w', 'f1m']):\n",
    "    results = []\n",
    "    if 'accuracy' in M:\n",
    "        results.append(metrics.accuracy_score(y, y_hat))\n",
    "    if 'precision' in M:\n",
    "        results.append(metrics.precision_score(y, y_hat))\n",
    "    if 'recall' in M:\n",
    "        results.append(metrics.recall_score(y, y_hat))\n",
    "    if 'f1w' in M:\n",
    "        results.append(metrics.f1_score(y, y_hat, average='weighted'))\n",
    "    if 'f1m' in M:\n",
    "        results.append(metrics.f1_score(y, y_hat, average='macro'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 0.08s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "with open(training_data, encoding='utf-8') as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    x_train_raw = []\n",
    "    y_train = []\n",
    "    for r in raw:\n",
    "        x_train_raw.append(r[1])\n",
    "        y_train.append(0 if r[2] == 'NOT' else 1)\n",
    "    x_train_raw = x_train_raw[1:]\n",
    "    y_train = y_train[1:]\n",
    "    \n",
    "with open(test_data, encoding='utf-8') as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    test_ids = []\n",
    "    x_test_raw = []\n",
    "    for r in raw:\n",
    "        test_ids.append(r[0])\n",
    "        x_test_raw.append(r[1])\n",
    "    test_ids = [int(i) for i in test_ids[1:]]\n",
    "    x_test_raw = x_test_raw[1:]\n",
    "        \n",
    "with open(test_labels, encoding='utf-8') as f:\n",
    "    raw = csv.reader(f, delimiter=',')\n",
    "    y_test = []\n",
    "    for r in raw:\n",
    "        y_test.append(0 if r[1] == 'NOT' else 1)\n",
    "    \n",
    "segmentations = {}\n",
    "for line in open(hashtags, encoding='utf-8'):\n",
    "    terms = [x.strip().lower() for x in line.split('\\t')]\n",
    "    hashtag, segmentation = terms[0], terms[1]\n",
    "    segmentations[hashtag] = segmentation\n",
    "    \n",
    "print('Loaded data in %.2fs' % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "class Wrapper:\n",
    "    def __init__(self, tweet_tk, segmentations):\n",
    "        self.tweet_tk = tweet_tk\n",
    "        self.segmentations = segmentations\n",
    "    \n",
    "    def tokenize(self, x):\n",
    "        tokens = []\n",
    "        for token in self.tweet_tk.tokenize(x):\n",
    "            if token[0] == '#' and token[1:] in self.segmentations:\n",
    "                sequence = self.segmentations[token[1:]].split()\n",
    "            else:\n",
    "                sequence = [token]\n",
    "\n",
    "            for word in sequence:\n",
    "                tokens.append(word)\n",
    "        return tokens\n",
    "tk = Wrapper(tokenizer, segmentations)\n",
    "          \n",
    "vectorizer = TfidfVectorizer(tokenizer=tk.tokenize, \n",
    "                             strip_accents='unicode', \n",
    "                             lowercase=True,\n",
    "                             sublinear_tf=True,\n",
    "                             min_df=9,\n",
    "                             stop_words='english'\n",
    "                            )\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_train_raw)\n",
    "x_test = vectorizer.transform(x_test_raw)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train, y_train = shuffle_together(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression-val.txt\n",
      "acc     p       r       f1w     f1m     time    \n",
      "0.8128  0.8435  0.4042  0.7884  0.7143  0.15s\n",
      "\n",
      "SVC-val.txt\n",
      "acc     p       r       f1w     f1m     time    \n",
      "0.8081  0.7622  0.4542  0.7908  0.7229  17.18s\n",
      "\n",
      "XGBClassifier-val.txt\n",
      "acc     p       r       f1w     f1m     time    \n",
      "0.8000  0.6789  0.5375  0.7922  0.7333  28.65s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final validation\n",
    "models = [\n",
    "    LogisticRegression(solver='lbfgs', max_iter=300),\n",
    "    SVC(kernel='linear', gamma='auto', C=1.8),\n",
    "    XGBClassifier(max_depth=3, learning_rate=0.63, n_estimators=1000)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    name = str(model).split('(')[0] + '-val.txt'\n",
    "    print(name)\n",
    "    print(6 * '%-8s' % ('acc', 'p', 'r', 'f1w', 'f1m', 'time'))\n",
    "    start = time()\n",
    "    clf = model.fit(x_train, y_train)\n",
    "    y_hat = clf.predict(x_test)\n",
    "    with open(name, 'w') as results:\n",
    "        for pred in y_hat:\n",
    "            results.write('%d\\n' % int(pred))\n",
    "    vals = report(y_test, y_hat) + [time() - start]\n",
    "    print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs\\n' % tuple(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
