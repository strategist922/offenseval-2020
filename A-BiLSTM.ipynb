{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "olid_data = 'data/OLIDv1.0/olid-training-v1.0.tsv'\n",
    "DEVICE = 0\n",
    "\n",
    "np.random.seed(1234) # helps reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    # https://discuss.pytorch.org/t/is-there-something-like-keras-utils-to-categorical-in-pytorch/5960\n",
    "    return np.eye(num_classes, dtype='uint8')[y]\n",
    "\n",
    "def report(y, y_hat, metrics=['accuracy', 'precision', 'recall', 'f1', 'auc']):\n",
    "    results = []\n",
    "    if 'accuracy' in metrics or 'acc' in metrics:\n",
    "        results.append(skmetrics.accuracy_score(y, y_hat))\n",
    "    if 'precision' in metrics:\n",
    "        results.append(skmetrics.precision_score(y, y_hat))\n",
    "    if 'recall' in metrics:\n",
    "        results.append(skmetrics.recall_score(y, y_hat))\n",
    "    if 'f1' in metrics:\n",
    "        results.append(skmetrics.f1_score(y, y_hat, average='weighted'))\n",
    "    if 'auc' in metrics:\n",
    "        results.append(skmetrics.roc_auc_score(y, y_hat))\n",
    "    return results\n",
    "\n",
    "# https://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console\n",
    "def printProgressBar (iteration, total, prefix='', suffix='', decimals=1, length=100, fill='█'):\n",
    "    '''\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    '''\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 2.09s\n"
     ]
    }
   ],
   "source": [
    "# y == 0 if not offensive\n",
    "# y == 1 if offensive\n",
    "start = time()\n",
    "with open(olid_data, encoding='utf-8') as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    x_raw = []\n",
    "    y = []\n",
    "    for r in raw:\n",
    "        x_raw.append(r[1])\n",
    "        y.append(0 if r[2] == 'NOT' else 1)\n",
    "    x_raw = x_raw[1:]\n",
    "    y = np.array(y[1:])\n",
    "    bad_words = [row[:-1] for row in f.readlines()[1:]]\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False)  \n",
    "x = []\n",
    "vocab = {}\n",
    "i = 0\n",
    "for tweet in x_raw:\n",
    "    example = []\n",
    "    for word in tokenizer.tokenize(tweet):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = i\n",
    "            i += 1\n",
    "        example.append(vocab[word])\n",
    "    x.append(example)\n",
    "    \n",
    "#Randomly shuffle\n",
    "i = np.arange(len(x))\n",
    "np.random.shuffle(i)\n",
    "x = [torch.LongTensor(x[k]).to(DEVICE) for k in i]\n",
    "y = torch.FloatTensor(to_categorical(y[i], 2)).to(DEVICE)\n",
    "\n",
    "split = 0.7\n",
    "split_index = int(len(x) * split)\n",
    "x_train = x[:split_index]\n",
    "y_train = y[:split_index]\n",
    "x_val = x[split_index:]\n",
    "y_val = y[split_index:]\n",
    "print('Loaded data in %.2fs' % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, X, Y, VOCAB_SIZE, DIM_EMB=10, NUM_CLASSES=2, device=0):\n",
    "        super(CNN, self).__init__()\n",
    "        (self.VOCAB_SIZE, self.DIM_EMB, self.NUM_CLASSES) = (VOCAB_SIZE, DIM_EMB, NUM_CLASSES)\n",
    "        self.device = device\n",
    "        \n",
    "        n1 = 200\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, DIM_EMB)\n",
    "        self.conv1_1 = nn.Conv1d(DIM_EMB, n1, 1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc = nn.Linear(n1, NUM_CLASSES)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, X, train=False):\n",
    "        x = self.embedding(X)\n",
    "        x = x.t()\n",
    "        # conv input: (batch_size, dim_emb, review_length)\n",
    "        x = x.view(1, x.shape[0], x.shape[1])\n",
    "        x = self.conv1_1(x)\n",
    "        # ccat output: (batch_size, dim_emb, review_length)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x.view(x.shape[1], 1))\n",
    "        x = self.act(x)\n",
    "        x = self.fc(x)\n",
    "        y = self.softmax(x)\n",
    "        return y\n",
    "    \n",
    "def Eval(X, Y, mlp):\n",
    "    num_correct = 0\n",
    "    for i in range(len(X)):\n",
    "        logProbs = mlp.forward(X[i], train=False)\n",
    "        pred = torch.argmax(logProbs)\n",
    "        onehot = np.zeros(2)\n",
    "        onehot[pred] = 1.\n",
    "        if (pred == Y[i]).all():\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / float(len(X))\n",
    "\n",
    "def Train(X, Y, val_X, val_Y, vocab_size, n_iter):\n",
    "    print(\"Start Training!\")\n",
    "    mlp = CNN(X, Y, vocab_size)\n",
    "    mlp.cuda()\n",
    "    optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "    batch_size = 1\n",
    "    max_acc = 0.5\n",
    "    for epoch in range(n_iter):\n",
    "        print('-------------')\n",
    "        print('Epoch %d' % epoch)\n",
    "        start = time()\n",
    "        total_loss = 0.0\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            mlp.zero_grad()\n",
    "            probs = mlp.forward(X[i])\n",
    "            y_onehot = Y[i]\n",
    "            loss = torch.neg(torch.log(probs)).dot(y_onehot)            \n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 10 == 0:\n",
    "                p = ' %d/%d' % (i, len(X))\n",
    "                printProgressBar(i+1, len(X), prefix=p, length=60)\n",
    "        print('loss: %.4f' % total_loss)\n",
    "        print('time: %.2fs' % (time() - start))\n",
    "        train_acc = Eval(X, Y, mlp)\n",
    "        val_acc = Eval(val_X, val_Y, mlp)\n",
    "        print('train_acc: %.4f' % train_acc)\n",
    "        print('val_acc: %.4f' % val_acc)\n",
    "        if val_acc > max_acc:\n",
    "            print('New best! Saving model.')\n",
    "            torch.save(mlp.state_dict(), 'best-epoch%d.model' % epoch)\n",
    "            max_acc = val_acc\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n",
      "-------------\n",
      "Epoch 0\n",
      "loss: 5967.6323████████████████████████████████████████████████████████-| 99.9% \n",
      "time: 45.83s\n",
      "train_acc: 0.0000\n",
      "val_acc: 0.0000\n",
      "-------------\n",
      "Epoch 1\n",
      "loss: 5164.7637████████████████████████████████████████████████████████-| 99.9% \n",
      "time: 45.46s\n",
      "train_acc: 0.0000\n",
      "val_acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "mlp = Train(x_train, y_train, x_val, y_val, len(vocab), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
