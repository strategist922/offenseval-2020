{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "olid_data = 'data/OLIDv1.0/olid-training-v1.0.tsv'\n",
    "kaggle_data_folder = 'data/jigsaw/'\n",
    "bad_words_data = 'data/trimmed-bad-words.txt'\n",
    "glove_data = 'data/glove.twitter.27B/glove.twitter.27B.25d.txt' # 25, 50, 100, or 200 D\n",
    "\n",
    "np.random.seed(1234) # help reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 1.92s\n"
     ]
    }
   ],
   "source": [
    "# y == 0 if not offensive\n",
    "# y == 1 if offensive\n",
    "start = time()\n",
    "with open(olid_data) as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    x_raw = []\n",
    "    y = []\n",
    "    for r in raw:\n",
    "        x_raw.append(r[1])\n",
    "        y.append(0 if r[2] == 'NOT' else 1)\n",
    "    x_raw = x_raw[1:]\n",
    "    y = np.array(y[1:])\n",
    "\n",
    "with open(kaggle_data_folder + 'train.csv') as f:  \n",
    "    raw = csv.reader(f, delimiter=',')\n",
    "    kaggle_x_raw = []\n",
    "    kaggle_y = []\n",
    "    for r in raw:\n",
    "        kaggle_x_raw.append(r[1])\n",
    "        kaggle_y.append(0 if all(x == '0' for x in r[2:]) else 1)\n",
    "    kaggle_x_raw = kaggle_x_raw[1:]\n",
    "    kaggle_y = np.array(kaggle_y[1:])\n",
    "     \n",
    "with open(bad_words_data) as f:\n",
    "    bad_words = [row[:-1] for row in f.readlines()[1:]]\n",
    "\n",
    "print('Loaded data in %.2fs' % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe in 25.22s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "glove = {}\n",
    "with open(glove_data) as f:\n",
    "    raw = [row.split() for row in f.readlines()]\n",
    "    for r in raw:\n",
    "        glove[r[0]] = np.array([float(v) for v in r[1:]])\n",
    "print('Loaded GloVe in %.2fs' % (time() - start))\n",
    "# On my mac, loads 25D in 30s, 50D in 100s, 100D in 630s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(x, y):\n",
    "    # Shuffle x and y together\n",
    "    state = np.random.get_state()\n",
    "    i = np.arange(x.shape[0])\n",
    "    np.random.shuffle(i)\n",
    "    np.random.set_state(state)\n",
    "    k = np.arange(y.shape[0])\n",
    "    np.random.shuffle(k)\n",
    "    return x[i, :], y[k] # shuffling a sparse matrix is weird\n",
    "\n",
    "def report(y, y_hat, metrics=['accuracy', 'precision', 'recall', 'f1', 'auc']):\n",
    "    results = []\n",
    "    if 'accuracy' in metrics or 'acc' in metrics:\n",
    "        results.append(skmetrics.accuracy_score(y, y_hat))\n",
    "    if 'precision' in metrics:\n",
    "        results.append(skmetrics.precision_score(y, y_hat))\n",
    "    if 'recall' in metrics:\n",
    "        results.append(skmetrics.recall_score(y, y_hat))\n",
    "    if 'f1' in metrics:\n",
    "        results.append(skmetrics.f1_score(y, y_hat, average='weighted'))\n",
    "    if 'auc' in metrics:\n",
    "        results.append(skmetrics.roc_auc_score(y, y_hat))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "          \n",
    "def bow():\n",
    "    # Build vocabulary from OLID data only\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                                 strip_accents='unicode', \n",
    "                                 lowercase=True,\n",
    "                                 sublinear_tf=True,\n",
    "                                 min_df=9,\n",
    "                                 stop_words='english'\n",
    "                                )\n",
    "    return vectorizer.fit_transform(x_raw)# + kaggle_x_raw)\n",
    "\n",
    "def sum_glove():\n",
    "    x = []\n",
    "    embedding = np.zeros(glove['.'].shape)\n",
    "    for tweet in x_raw:\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        for word in tokens:\n",
    "            if word in glove:\n",
    "                embedding += glove[word]\n",
    "        x.append(embedding)#/ len(tokens))\n",
    "    x = np.array(x)\n",
    "    x = x - np.min(x, axis=1).reshape(x.shape[0], 1)\n",
    "    x = x / np.max(x, axis=1).reshape(x.shape[0], 1)\n",
    "    return np.array(x)\n",
    "\n",
    "x = bow()\n",
    "# kaggle_x = x[len(x_raw):]\n",
    "# x = x[:len(x_raw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "def test(model):\n",
    "    k = 10\n",
    "    kf = KFold(n_splits=k)\n",
    "    average_acc = 0\n",
    "    print(6 * '%-8s' % ('acc', 'p', 'r', 'f1', 'auc', 'time'))\n",
    "    averages = np.array([0] * 6, dtype='float')\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        start = time()\n",
    "        # Split based on k-fold\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Append kaggle data to training data\n",
    "        # x_train = vstack((x_train, kaggle_x))\n",
    "        # y_train = np.concatenate((y_train, kaggle_y))\n",
    "        x_train, y_train = shuffle_together(x_train, y_train)\n",
    "        clf = model.fit(x_train, y_train)\n",
    "        y_hat = clf.predict(x_test)\n",
    "        vals = report(y_test, y_hat) + [time() - start]\n",
    "        averages += vals\n",
    "        print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs' % tuple(vals))\n",
    "    print('average:')\n",
    "    averages /= k\n",
    "    print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs' % tuple(averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "acc     p       r       f1      auc     time    \n",
      "0.7462  0.7371  0.3834  0.7200  0.6570  0.15s\n",
      "0.7711  0.7991  0.4221  0.7480  0.6844  0.16s\n",
      "0.7636  0.8259  0.4304  0.7403  0.6899  0.15s\n",
      "0.7598  0.6971  0.3625  0.7332  0.6472  0.14s\n",
      "0.7644  0.7773  0.4055  0.7398  0.6739  0.15s\n",
      "0.7734  0.8249  0.4059  0.7476  0.6814  0.21s\n",
      "0.7795  0.8178  0.4089  0.7545  0.6827  0.12s\n",
      "0.7598  0.8018  0.3938  0.7328  0.6717  0.12s\n",
      "0.7719  0.8000  0.4119  0.7476  0.6806  0.17s\n",
      "0.7613  0.7541  0.4182  0.7390  0.6752  0.20s\n",
      "average:\n",
      "0.7651  0.7835  0.4043  0.7403  0.6744  0.16s\n",
      "\n",
      "SVM\n",
      "acc     p       r       f1      auc     time    \n",
      "0.7576  0.7076  0.4776  0.7433  0.6887  12.31s\n",
      "0.7757  0.7310  0.5214  0.7645  0.7125  12.04s\n",
      "0.7681  0.7702  0.5021  0.7540  0.7093  12.42s\n",
      "0.7681  0.6729  0.4525  0.7531  0.6786  12.35s\n",
      "0.7711  0.7446  0.4715  0.7550  0.6957  12.63s\n",
      "0.7772  0.7417  0.5079  0.7645  0.7098  13.08s\n",
      "0.7802  0.7354  0.5000  0.7671  0.7070  21.12s\n",
      "0.7659  0.7432  0.4801  0.7505  0.6970  22.69s\n",
      "0.7719  0.7352  0.4828  0.7572  0.6986  22.58s\n",
      "0.7651  0.7022  0.5091  0.7539  0.7008  14.10s\n",
      "average:\n",
      "0.7701  0.7284  0.4905  0.7563  0.6998  15.53s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('Logistic Regression')\n",
    "test(LogisticRegression(solver='lbfgs', max_iter=300))\n",
    "print()\n",
    "print('SVM')\n",
    "test(SVC(kernel='linear', gamma='auto', C=1.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
