{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "olid_data = 'data/OLIDv1.0/olid-training-v1.0.tsv'\n",
    "olid_hashtags = 'data/olid_segmentations.tsv'\n",
    "kaggle_data_folder = 'data/jigsaw/'\n",
    "bad_words_data = 'data/trimmed-bad-words.txt'\n",
    "glove_data = 'data/glove.twitter.27B/glove.twitter.27B.25d.txt' # 25, 50, 100, or 200 D\n",
    "\n",
    "np.random.seed(1234) # help reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 0.05s\n"
     ]
    }
   ],
   "source": [
    "# y == 0 if not offensive\n",
    "# y == 1 if offensive\n",
    "start = time()\n",
    "with open(olid_data, encoding='utf-8') as f:\n",
    "    raw = csv.reader(f, delimiter='\\t')\n",
    "    x_raw = []\n",
    "    y = []\n",
    "    for r in raw:\n",
    "        x_raw.append(r[1])\n",
    "        y.append(0 if r[2] == 'NOT' else 1)\n",
    "    x_raw = x_raw[1:]\n",
    "    y = np.array(y[1:])\n",
    "\n",
    "'''\n",
    "with open(kaggle_data_folder + 'train.csv', encoding='utf-8') as f:  \n",
    "    raw = csv.reader(f, delimiter=',')\n",
    "    kaggle_x_raw = []\n",
    "    kaggle_y = []\n",
    "    for r in raw:\n",
    "        kaggle_x_raw.append(r[1])\n",
    "        kaggle_y.append(0 if all(x == '0' for x in r[2:]) else 1)\n",
    "    kaggle_x_raw = kaggle_x_raw[1:]\n",
    "    kaggle_y = np.array(kaggle_y[1:])\n",
    "'''\n",
    "\n",
    "# Load hashtag segmentations\n",
    "segmentations = {}\n",
    "for line in open(olid_hashtags, encoding='utf-8'):\n",
    "    terms = [x.strip().lower() for x in line.split('\\t')]\n",
    "    hashtag, segmentation = terms[0], terms[1]\n",
    "    segmentations[hashtag] = segmentation\n",
    "\n",
    "print('Loaded data in %.2fs' % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(x, y):\n",
    "    # Shuffle x and y together\n",
    "    i = np.arange(x.shape[0])\n",
    "    np.random.shuffle(i)\n",
    "    return x[i, :], y[i], i # shuffling a sparse matrix is weird\n",
    "\n",
    "def report(y, y_hat, metrics=['accuracy', 'precision', 'recall', 'f1', 'auc']):\n",
    "    results = []\n",
    "    if 'accuracy' in metrics or 'acc' in metrics:\n",
    "        results.append(skmetrics.accuracy_score(y, y_hat))\n",
    "    if 'precision' in metrics:\n",
    "        results.append(skmetrics.precision_score(y, y_hat))\n",
    "    if 'recall' in metrics:\n",
    "        results.append(skmetrics.recall_score(y, y_hat))\n",
    "    if 'f1' in metrics:\n",
    "        results.append(skmetrics.f1_score(y, y_hat, average='weighted'))\n",
    "    if 'auc' in metrics:\n",
    "        results.append(skmetrics.f1_score(y, y_hat, average='macro'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "class Wrapper:\n",
    "    def __init__(self, tweet_tk, segmentations):\n",
    "        self.tweet_tk = tweet_tk\n",
    "        self.segmentations = segmentations\n",
    "    \n",
    "    def tokenize(self, x):\n",
    "        tokens = []\n",
    "        for token in self.tweet_tk.tokenize(x):\n",
    "            if token[0] == '#' and token[1:] in self.segmentations:\n",
    "                sequence = self.segmentations[token[1:]].split()\n",
    "            else:\n",
    "                sequence = [token]\n",
    "\n",
    "            for word in sequence:\n",
    "                tokens.append(word)\n",
    "        return tokens\n",
    "tk = Wrapper(tokenizer, segmentations)\n",
    "          \n",
    "def bow():\n",
    "    # Build vocabulary from OLID data only\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tk.tokenize, \n",
    "                                 strip_accents='unicode', \n",
    "                                 lowercase=True,\n",
    "                                 sublinear_tf=True,\n",
    "                                 min_df=9,\n",
    "                                 stop_words='english'\n",
    "                                )\n",
    "    return vectorizer.fit_transform(x_raw)# + kaggle_x_raw)\n",
    "\n",
    "def sum_glove():\n",
    "    x = []\n",
    "    embedding = np.zeros(glove['.'].shape)\n",
    "    for tweet in x_raw:\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        for word in tokens:\n",
    "            if word in glove:\n",
    "                embedding += glove[word]\n",
    "        x.append(embedding)#/ len(tokens))\n",
    "    x = np.array(x)\n",
    "    x = x - np.min(x, axis=1).reshape(x.shape[0], 1)\n",
    "    x = x / np.max(x, axis=1).reshape(x.shape[0], 1)\n",
    "    return np.array(x)\n",
    "\n",
    "x = bow()\n",
    "# kaggle_x = x[len(x_raw):]\n",
    "# x = x[:len(x_raw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "def test(model):\n",
    "    k = 10\n",
    "    kf = KFold(n_splits=k)\n",
    "    average_acc = 0\n",
    "    print(6 * '%-8s' % ('acc', 'p', 'r', 'f1w', 'f1m', 'time'))\n",
    "    averages = np.array([0] * 6, dtype='float')\n",
    "    name = str(model).split('(')[0] + '.txt'\n",
    "    results = open(name, 'w')\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        start = time()\n",
    "        # Split based on k-fold\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Append kaggle data to training data\n",
    "        # x_train = vstack((x_train, kaggle_x))\n",
    "        # y_train = np.concatenate((y_train, kaggle_y))\n",
    "        x_train, y_train, i = shuffle_together(x_train, y_train)\n",
    "        clf = model.fit(x_train, y_train)\n",
    "        y_hat = clf.predict(x_test)\n",
    "        for pred in y_hat:\n",
    "            results.write('%d\\n' % int(pred))\n",
    "        vals = report(y_test, y_hat) + [time() - start]\n",
    "        averages += vals\n",
    "        print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs' % tuple(vals))\n",
    "    results.close()\n",
    "    print('average:')\n",
    "    averages /= k\n",
    "    print('%.4f  %.4f  %.4f  %.4f  %.4f  %.2fs' % tuple(averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "acc     p       r       f1w     f1m     time    \n",
      "0.7470  0.7445  0.3789  0.7198  0.6663  0.13s\n",
      "0.7704  0.8009  0.4176  0.7466  0.6975  0.12s\n",
      "0.7613  0.8086  0.4367  0.7393  0.7012  0.12s\n",
      "0.7598  0.7010  0.3575  0.7324  0.6590  0.12s\n",
      "0.7591  0.7632  0.3964  0.7338  0.6804  0.12s\n",
      "0.7711  0.8165  0.4036  0.7453  0.6939  0.13s\n",
      "0.7863  0.8281  0.4276  0.7632  0.7112  0.12s\n",
      "0.7568  0.7928  0.3894  0.7295  0.6796  0.12s\n",
      "0.7787  0.8186  0.4233  0.7552  0.7052  0.14s\n",
      "0.7606  0.7531  0.4159  0.7380  0.6873  0.12s\n",
      "average:\n",
      "0.7651  0.7827  0.4047  0.7403  0.6881  0.12s\n",
      "\n",
      "SVM\n",
      "acc     p       r       f1w     f1m     time    \n",
      "0.7560  0.7071  0.4709  0.7411  0.6979  11.60s\n",
      "0.7757  0.7370  0.5124  0.7635  0.7240  11.46s\n",
      "0.7704  0.7724  0.5084  0.7567  0.7250  11.54s\n",
      "0.7674  0.6667  0.4600  0.7533  0.6941  11.58s\n",
      "0.7719  0.7438  0.4761  0.7562  0.7120  11.57s\n",
      "0.7757  0.7400  0.5034  0.7626  0.7217  11.90s\n",
      "0.7885  0.7483  0.5210  0.7767  0.7343  12.57s\n",
      "0.7606  0.7368  0.4646  0.7439  0.7020  13.63s\n",
      "0.7659  0.7138  0.4851  0.7521  0.7078  12.32s\n",
      "0.7711  0.7121  0.5227  0.7607  0.7211  12.67s\n",
      "average:\n",
      "0.7703  0.7278  0.4925  0.7567  0.7140  12.08s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('Logistic Regression')\n",
    "test(LogisticRegression(solver='lbfgs', max_iter=300))\n",
    "print()\n",
    "print('SVM')\n",
    "test(SVC(kernel='linear', gamma='auto', C=1.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
